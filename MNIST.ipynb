{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP1OqRCO4GYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25b0029d-389b-47e9-f31a-c2e40a83a409"
      },
      "source": [
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, Convolution2D, MaxPooling2D, Concatenate\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Model\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "nb_epochs = 12\n",
        "nb_filters = 64\n",
        "my_optimizer = 'adadelta' # proved better than 'adam' in my experiments\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# In 2D, \"channels_last\" assumes (rows, cols, channels) while \"channels_first\" assumes (channels, rows, cols). \n",
        "\n",
        "# there is only one channel here (levels of grey), so we need to create a dim here\n",
        "# for color pictures we would have 3: RGB\n",
        "\n",
        "# option 'channels last'\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\t\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "my_max = np.amax(x_train)\n",
        "\n",
        "x_train /= my_max # divide by 255 (max value) to have all values between 0 and 1\n",
        "x_test /= my_max\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# transforms integers labels into one-hot flags of length ncol\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "my_input = Input(shape=input_shape, dtype='float32')\n",
        "\n",
        "conv_1 = Convolution2D(nb_filters, 3, 3, # region size is (3, 3)\n",
        "                       border_mode = 'valid',\n",
        "\t\t\t\t\t   activation = 'relu', \n",
        "                       #input_shape=input_shape\n",
        "\t\t\t\t\t  ) (my_input)\n",
        "# output is of dim  [(w - f + 2p) / s] + 1, where w is input size, f is filter size, s is stride, and p is amount of zero padding\n",
        "# [28 - 3 + 2*0 / 1] + 1 \n",
        "\n",
        "pooled_conv_1 = MaxPooling2D(pool_size=(2,2)) (conv_1)\n",
        "pooled_conv_1_dropped = Dropout(0.2) (pooled_conv_1)\n",
        "\n",
        "conv_11 = Convolution2D(nb_filters, 3, 3,\n",
        "                       border_mode = 'valid',\n",
        "\t\t\t\t\t   activation = 'relu', \n",
        "                       #input_shape=input_shape\n",
        "\t\t\t\t\t  ) (pooled_conv_1_dropped)\n",
        "pooled_conv_11 = MaxPooling2D(pool_size=(2,2)) (conv_11)\n",
        "pooled_conv_11_dropped = Dropout(0.2) (pooled_conv_11)\n",
        "\n",
        "pooled_conv_11_dropped_flat = Flatten()(pooled_conv_11_dropped)\n",
        "\n",
        "# increasing the number of different filter sizes proved better than increasing depth of each individually in my experiments\n",
        "\n",
        "# ====\n",
        "\n",
        "conv_2 = Convolution2D(nb_filters, 4, 4, \n",
        "                       border_mode = 'valid',\n",
        "\t\t\t\t\t   activation = 'relu', \n",
        "                       #input_shape=input_shape\n",
        "\t\t\t\t\t  ) (my_input)\n",
        "pooled_conv_2 = MaxPooling2D(pool_size=(2,2)) (conv_2)\n",
        "pooled_conv_2_dropped = Dropout(0.2) (pooled_conv_2)\n",
        "\n",
        "conv_22 = Convolution2D(nb_filters, 4, 4, \n",
        "                       border_mode = 'valid',\n",
        "\t\t\t\t\t   activation = 'relu', \n",
        "                       #input_shape=input_shape\n",
        "\t\t\t\t\t  ) (pooled_conv_2_dropped)\n",
        "pooled_conv_22 = MaxPooling2D(pool_size=(2,2)) (conv_22)\n",
        "pooled_conv_22_dropped = Dropout(0.2) (pooled_conv_22)\n",
        "\n",
        "pooled_conv_22_dropped_flat = Flatten()(pooled_conv_22_dropped)\n",
        "\n",
        "# ====\n",
        "\n",
        "conv_3 = Convolution2D(nb_filters, 5, 5, \n",
        "                       border_mode = 'valid',\n",
        "\t\t\t\t\t   activation = 'relu', \n",
        "                       #input_shape=input_shape\n",
        "\t\t\t\t\t  ) (my_input)\n",
        "pooled_conv_3 = MaxPooling2D(pool_size=(2,2)) (conv_3)\n",
        "pooled_conv_3_dropped = Dropout(0.2) (pooled_conv_3)\n",
        "\n",
        "conv_33 = Convolution2D(nb_filters, 2, 2, \n",
        "                       border_mode = 'valid',\n",
        "\t\t\t\t\t   activation = 'relu', \n",
        "                       #input_shape=input_shape\n",
        "\t\t\t\t\t  ) (pooled_conv_3_dropped)\n",
        "pooled_conv_33 = MaxPooling2D(pool_size=(2,2)) (conv_33)\n",
        "pooled_conv_33_dropped = Dropout(0.2) (pooled_conv_33)\n",
        "\n",
        "pooled_conv_33_dropped_flat = Flatten()(pooled_conv_33_dropped)\n",
        "\n",
        "# ====\n",
        "\n",
        "# ====\n",
        "\n",
        "conv_4 = Convolution2D(nb_filters, 6, 6, \n",
        "                       border_mode = 'valid',\n",
        "\t\t\t\t\t   activation = 'relu', \n",
        "                       #input_shape=input_shape\n",
        "\t\t\t\t\t  ) (my_input)\n",
        "pooled_conv_4 = MaxPooling2D(pool_size=(2,2)) (conv_4)\n",
        "pooled_conv_4_dropped = Dropout(0.2) (pooled_conv_4)\n",
        "\n",
        "conv_44 = Convolution2D(nb_filters, 6, 6, \n",
        "                       border_mode = 'valid',\n",
        "\t\t\t\t\t   activation = 'relu', \n",
        "                       #input_shape=input_shape\n",
        "\t\t\t\t\t  ) (pooled_conv_4_dropped)\n",
        "pooled_conv_44 = MaxPooling2D(pool_size=(2,2)) (conv_44)\n",
        "pooled_conv_44_dropped = Dropout(0.2) (pooled_conv_44)\n",
        "\n",
        "pooled_conv_44_dropped_flat = Flatten()(pooled_conv_44_dropped)\n",
        "\n",
        "# ====\n",
        "\n",
        "merge = Concatenate() ([pooled_conv_11_dropped_flat,pooled_conv_22_dropped_flat,pooled_conv_33_dropped_flat,pooled_conv_44_dropped_flat])\n",
        "merge_dropped = Dropout(0.2) (merge)\n",
        "\n",
        "dense = Dense(128,\n",
        "             activation='relu'\n",
        "\t\t\t) (merge_dropped)\n",
        "dense_dropped = Dropout(0.2) (dense)\n",
        "\n",
        "prob = Dense(output_dim = num_classes, # we output a prob distribution over the classes\n",
        "             activation='softmax'\n",
        "\t\t\t) (dense_dropped)\n",
        "\n",
        "model = Model(my_input, prob)\n",
        "\n",
        "print([layer.output_shape for layer in model.layers])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "\t\t\t  optimizer=my_optimizer,\n",
        "\t\t\t  metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, \n",
        "\t\t  y_train, \n",
        "\t\t  batch_size = batch_size, \n",
        "\t\t  nb_epoch = nb_epochs,\n",
        "\t\t  validation_data = (x_test, y_test)\n",
        "\t\t )\n",
        "\t\t  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"valid\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"valid\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), activation=\"relu\", padding=\"valid\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), activation=\"relu\", padding=\"valid\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:112: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=\"relu\", padding=\"valid\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:120: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (2, 2), activation=\"relu\", padding=\"valid\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:134: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (6, 6), activation=\"relu\", padding=\"valid\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:142: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (6, 6), activation=\"relu\", padding=\"valid\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[(None, 28, 28, 1), (None, 26, 26, 64), (None, 25, 25, 64), (None, 24, 24, 64), (None, 23, 23, 64), (None, 13, 13, 64), (None, 12, 12, 64), (None, 12, 12, 64), (None, 11, 11, 64), (None, 13, 13, 64), (None, 12, 12, 64), (None, 12, 12, 64), (None, 11, 11, 64), (None, 11, 11, 64), (None, 9, 9, 64), (None, 11, 11, 64), (None, 6, 6, 64), (None, 5, 5, 64), (None, 4, 4, 64), (None, 5, 5, 64), (None, 3, 3, 64), (None, 5, 5, 64), (None, 4, 4, 64), (None, 5, 5, 64), (None, 3, 3, 64), (None, 1600), (None, 1024), (None, 1600), (None, 576), (None, 4800), (None, 4800), (None, 128), (None, 128), (None, 10)]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:161: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:176: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 28s 469us/step - loss: 0.1710 - acc: 0.9457 - val_loss: 0.0370 - val_acc: 0.9881\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.0538 - acc: 0.9838 - val_loss: 0.0357 - val_acc: 0.9878\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0395 - acc: 0.9880 - val_loss: 0.0258 - val_acc: 0.9914\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0333 - acc: 0.9894 - val_loss: 0.0210 - val_acc: 0.9929\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.0291 - acc: 0.9908 - val_loss: 0.0225 - val_acc: 0.9924\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0245 - acc: 0.9927 - val_loss: 0.0220 - val_acc: 0.9938\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.0208 - acc: 0.9935 - val_loss: 0.0205 - val_acc: 0.9937\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.0226 - val_acc: 0.9928\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.0180 - acc: 0.9947 - val_loss: 0.0197 - val_acc: 0.9943\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0150 - acc: 0.9953 - val_loss: 0.0205 - val_acc: 0.9937\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0203 - val_acc: 0.9938\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0132 - acc: 0.9961 - val_loss: 0.0217 - val_acc: 0.9935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6a1412d6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILiKWzVk4Xxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gf_4iY26ZLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}