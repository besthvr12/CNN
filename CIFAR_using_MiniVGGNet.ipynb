{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR using MiniVGGNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGoQmj_RT89k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "5dbe0c5c-a40e-46c1-c7b9-025e17a01a55"
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch0bbGOgUG-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width=32\n",
        "height=32\n",
        "depth=3\n",
        "classes=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-EN8t9sUJG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = 1\n",
        "\n",
        "# if we are using \"channels first\", update the input shape\n",
        "# and channels dimension\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EewUEGBJUK3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first CONV => RELU => CONV => RELU => POOL layer set\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
        "input_shape=inputShape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbS-f8iXUNCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# second CONV => RELU => CONV => RELU => POOL layer set\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "521j4OFQUPGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first (and only) set of FC => RELU layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_nYrfn7UVnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# softmax classifier\n",
        "model.add(Dense(classes))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2EblmGIUXJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhDFW8PYUZFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjB5IzNRUa4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a37c4df-cd1d-4d7d-d9de-36f51e8763d4"
      },
      "source": [
        "# load the training and testing data, then scale it into the\n",
        "# range [0, 1]\n",
        "print(\"[INFO] loading CIFAR-10 data...\")\n",
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
        "\n",
        "trainX = trainX.astype(\"float\") / 255.0\n",
        "testX = testX.astype(\"float\") / 255.0\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "\n",
        "# initialize the label names for the CIFAR-10 dataset\n",
        "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        " \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading CIFAR-10 data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgg7yWV7Ucio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9eb9bb4-8cc4-4c2d-97aa-77a1d8116f07"
      },
      "source": [
        "#initialize the optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=0.01, decay=0.01 / 40, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        " # train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=40, verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "[INFO] training network...\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "50000/50000 [==============================] - 15s 290us/step - loss: 2.1147 - acc: 0.2730 - val_loss: 2.1037 - val_acc: 0.2608\n",
            "Epoch 2/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 1.6093 - acc: 0.4177 - val_loss: 1.4052 - val_acc: 0.4896\n",
            "Epoch 3/40\n",
            "50000/50000 [==============================] - 9s 183us/step - loss: 1.3339 - acc: 0.5260 - val_loss: 1.2417 - val_acc: 0.5605\n",
            "Epoch 4/40\n",
            "50000/50000 [==============================] - 9s 185us/step - loss: 1.1843 - acc: 0.5786 - val_loss: 1.1433 - val_acc: 0.6025\n",
            "Epoch 5/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 1.0592 - acc: 0.6242 - val_loss: 0.9076 - val_acc: 0.6810\n",
            "Epoch 6/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 0.9737 - acc: 0.6564 - val_loss: 0.9498 - val_acc: 0.6686\n",
            "Epoch 7/40\n",
            "50000/50000 [==============================] - 9s 179us/step - loss: 0.9050 - acc: 0.6804 - val_loss: 0.8286 - val_acc: 0.7018\n",
            "Epoch 8/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 0.8514 - acc: 0.6986 - val_loss: 0.7733 - val_acc: 0.7298\n",
            "Epoch 9/40\n",
            "50000/50000 [==============================] - 9s 183us/step - loss: 0.8043 - acc: 0.7159 - val_loss: 0.8647 - val_acc: 0.7023\n",
            "Epoch 10/40\n",
            "50000/50000 [==============================] - 9s 183us/step - loss: 0.7672 - acc: 0.7293 - val_loss: 0.7725 - val_acc: 0.7320\n",
            "Epoch 11/40\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.7381 - acc: 0.7390 - val_loss: 0.7040 - val_acc: 0.7487\n",
            "Epoch 12/40\n",
            "50000/50000 [==============================] - 9s 185us/step - loss: 0.7048 - acc: 0.7521 - val_loss: 0.7124 - val_acc: 0.7603\n",
            "Epoch 13/40\n",
            "50000/50000 [==============================] - 9s 184us/step - loss: 0.6790 - acc: 0.7613 - val_loss: 0.6873 - val_acc: 0.7569\n",
            "Epoch 14/40\n",
            "50000/50000 [==============================] - 9s 183us/step - loss: 0.6568 - acc: 0.7690 - val_loss: 0.6703 - val_acc: 0.7701\n",
            "Epoch 15/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 0.6303 - acc: 0.7759 - val_loss: 0.6625 - val_acc: 0.7706\n",
            "Epoch 16/40\n",
            "50000/50000 [==============================] - 9s 180us/step - loss: 0.6143 - acc: 0.7826 - val_loss: 0.6373 - val_acc: 0.7779\n",
            "Epoch 17/40\n",
            "50000/50000 [==============================] - 9s 184us/step - loss: 0.5907 - acc: 0.7904 - val_loss: 0.6348 - val_acc: 0.7819\n",
            "Epoch 18/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 0.5755 - acc: 0.7958 - val_loss: 0.6204 - val_acc: 0.7844\n",
            "Epoch 19/40\n",
            "50000/50000 [==============================] - 9s 181us/step - loss: 0.5563 - acc: 0.8026 - val_loss: 0.6294 - val_acc: 0.7842\n",
            "Epoch 20/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 0.5456 - acc: 0.8080 - val_loss: 0.6406 - val_acc: 0.7796\n",
            "Epoch 21/40\n",
            "50000/50000 [==============================] - 9s 183us/step - loss: 0.5298 - acc: 0.8131 - val_loss: 0.6257 - val_acc: 0.7852\n",
            "Epoch 22/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 0.5238 - acc: 0.8140 - val_loss: 0.5935 - val_acc: 0.7959\n",
            "Epoch 23/40\n",
            "50000/50000 [==============================] - 9s 180us/step - loss: 0.5060 - acc: 0.8190 - val_loss: 0.6366 - val_acc: 0.7846\n",
            "Epoch 24/40\n",
            "50000/50000 [==============================] - 9s 184us/step - loss: 0.4958 - acc: 0.8227 - val_loss: 0.6195 - val_acc: 0.7847\n",
            "Epoch 25/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 0.4855 - acc: 0.8275 - val_loss: 0.5961 - val_acc: 0.7949\n",
            "Epoch 26/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 0.4754 - acc: 0.8309 - val_loss: 0.6115 - val_acc: 0.7945\n",
            "Epoch 27/40\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.4676 - acc: 0.8332 - val_loss: 0.5984 - val_acc: 0.7989\n",
            "Epoch 28/40\n",
            "50000/50000 [==============================] - 9s 183us/step - loss: 0.4550 - acc: 0.8375 - val_loss: 0.5842 - val_acc: 0.8011\n",
            "Epoch 29/40\n",
            "50000/50000 [==============================] - 9s 182us/step - loss: 0.4492 - acc: 0.8419 - val_loss: 0.6194 - val_acc: 0.7926\n",
            "Epoch 30/40\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.4353 - acc: 0.8441 - val_loss: 0.5915 - val_acc: 0.7977\n",
            "Epoch 31/40\n",
            "50000/50000 [==============================] - 9s 183us/step - loss: 0.4292 - acc: 0.8482 - val_loss: 0.5882 - val_acc: 0.8011\n",
            "Epoch 32/40\n",
            "50000/50000 [==============================] - 9s 183us/step - loss: 0.4229 - acc: 0.8484 - val_loss: 0.5929 - val_acc: 0.8036\n",
            "Epoch 33/40\n",
            "50000/50000 [==============================] - 9s 181us/step - loss: 0.4136 - acc: 0.8538 - val_loss: 0.6133 - val_acc: 0.7956\n",
            "Epoch 34/40\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.4019 - acc: 0.8560 - val_loss: 0.5934 - val_acc: 0.8004\n",
            "Epoch 35/40\n",
            "50000/50000 [==============================] - 9s 183us/step - loss: 0.3992 - acc: 0.8560 - val_loss: 0.5775 - val_acc: 0.8057\n",
            "Epoch 36/40\n",
            "50000/50000 [==============================] - 9s 183us/step - loss: 0.3872 - acc: 0.8609 - val_loss: 0.5957 - val_acc: 0.8055\n",
            "Epoch 37/40\n",
            "50000/50000 [==============================] - 9s 185us/step - loss: 0.3882 - acc: 0.8609 - val_loss: 0.6006 - val_acc: 0.8036\n",
            "Epoch 38/40\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.3748 - acc: 0.8656 - val_loss: 0.5951 - val_acc: 0.8007\n",
            "Epoch 39/40\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.3764 - acc: 0.8678 - val_loss: 0.5822 - val_acc: 0.8097\n",
            "Epoch 40/40\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.3685 - acc: 0.8671 - val_loss: 0.5692 - val_acc: 0.8083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQA2wI8XUt7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}